{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_sgd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYzbcYildXAxsH5bsf08GG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BoshiLee/pytorch_learning/blob/main/iris_sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import package and dataset"
      ],
      "metadata": {
        "id": "C8Hk__yjEgRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1OA9DnDV_h5",
        "outputId": "5abce6b6-e171-4eac-df01-ee3852436d06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l2Qoo2m0EOE5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn import datasets\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data = datasets.load_iris()\n",
        "input_data = iris_data.data\n",
        "target = iris_data.target\n",
        "\n",
        "n_data = len(target)"
      ],
      "metadata": {
        "id": "06VmAyeDEfpn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target To hot-laybel format"
      ],
      "metadata": {
        "id": "FwuG6BlPkb5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target\n",
        "\n",
        "\n",
        "def to_hot_label(t):\n",
        "  temp = np.zeros((len(t), 3))\n",
        "  for i in range(len(t)):\n",
        "    temp[i, t[i]] = 1\n",
        "  return torch.tensor(temp)\n",
        "\n",
        "target_data = to_hot_label(target)\n"
      ],
      "metadata": {
        "id": "DZUSHXPtdKWJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization 歸一\n",
        "\n",
        "\b(樣本 - 樣本平均值) / 標準差"
      ],
      "metadata": {
        "id": "uPDwsvRVUnp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.extras import median\n",
        "mean_input = np.average(input_data, axis=0)\n",
        "std_input = np.std(input_data, axis=0)\n",
        "\n",
        "input_data = (input_data - mean_input) / std_input"
      ],
      "metadata": {
        "id": "FwCSJtkWcNJk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apart Datasets to Test and Training"
      ],
      "metadata": {
        "id": "6J84MdoUlif5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_idx = np.arange(n_data)\n",
        "index_train = all_idx[all_idx % 2 == 0] # 0,2,4,6...\n",
        "index_test = all_idx[all_idx % 2 != 0] # 1,3,5\n",
        "\n",
        "input_train = input_data[index_train, :]\n",
        "input_test = input_data[index_test, :]\n",
        "\n",
        "target_train = target_data[index_train, :]\n",
        "target_test = target_data[index_test, :]\n",
        "\n",
        "n_part = len(target_train)\n",
        "\n",
        "class IrisDataset(Dataset):\n",
        "    def __init__(self,X,Y):\n",
        "        self.X = X                           # set data\n",
        "        self.Y = Y                           # set lables\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)                   # return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return [self.X[idx], self.Y[idx]] \n",
        "\n"
      ],
      "metadata": {
        "id": "V9tX2FQp2Pgm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = IrisDataset(input_train, target_train)\n",
        "validation_dataset = IrisDataset(input_test, target_test)"
      ],
      "metadata": {
        "id": "QCyDKBQ4p0kn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define hyper parameters"
      ],
      "metadata": {
        "id": "5czj84xHUDOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_in = 4 # 輸入\n",
        "n_mid = 25 # 中間層\n",
        "n_out = 3 # 輸出\n",
        "\n",
        "wb_width = 0.1 #\n",
        "eta = 0.01 # 學習率\n",
        "epochs = 1000\n",
        "batch_size = 8\n",
        "interval = 100\n"
      ],
      "metadata": {
        "id": "d3kqGjVNUKCy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size =batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "FKwB7cYBma-G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model\n",
        "\n",
        "In middle layer, I chose reLU for active function and softmax for output layer to classfication model results."
      ],
      "metadata": {
        "id": "tfJLvDy7ia_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, D_in, H1, D_out):\n",
        "    super().__init__();\n",
        "    self.linear1 = nn.Linear(D_in, H1)\n",
        "    self.linear2 = nn.Linear(H1, H1)\n",
        "    self.linear3 = nn.Linear(H1, D_out)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.linear1(x)) # 輸入位給第一層 hidden layer 後再將輸出給下一層用\n",
        "    x = F.relu(self.linear2(x)) # 輸入位給第二層 hidden layer 給輸出曾使用\n",
        "    x = self.linear3(x) # 這裡不用 softmax 去做分類，課程是說等等可以用原始輸出給 nn.CrossEntropyLoss\n",
        "    return x"
      ],
      "metadata": {
        "id": "V2dZrNJ3WyVE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initail Model"
      ],
      "metadata": {
        "id": "4eQWNzXLjfsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(n_in, n_mid, n_out) \n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B57SFp2vjhkI",
        "outputId": "bcac1591-7f20-4e2a-e20f-71bff63fb840"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (linear1): Linear(in_features=4, out_features=25, bias=True)\n",
              "  (linear2): Linear(in_features=25, out_features=25, bias=True)\n",
              "  (linear3): Linear(in_features=25, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = eta)"
      ],
      "metadata": {
        "id": "C9Jo5I1Imz6W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss_history = []\n",
        "running_correct_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_correct_history = []\n",
        "\n",
        "def record_epoch(title:str, losses, corrects, loader_lenth):\n",
        "  print(loader_lenth)\n",
        "  epoch_loss = losses / loader_lenth # 將損失總數除上一個 batch 的資料總數就可以到此次 batch 訓練出來損失多少\n",
        "  epoch_accuracy = corrects.float() / loader_lenth\n",
        "\n",
        "  print(title + \" loss: {:.4f}\".format(epoch_loss))\n",
        "  print(title + \" accuracy: {:.4f}\".format(epoch_accuracy.item()))\n",
        "\n",
        "  return epoch_loss, epoch_accuracy\n",
        "\n",
        "\n",
        "def traing_process():\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  val_running_loss = 0.0\n",
        "  val_running_corrects = 0.0\n",
        "  for (inputs, labels) in training_loader:\n",
        "    outputs = model.forward(inputs.float())\n",
        "    loss = criterion(outputs, labels) #loss function\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, preds = torch.max(outputs, dim=1) #返回每一列中最大值的那个元素，且返回索引（返回最大元素在这一列的行索引）\n",
        "    preds = to_hot_label(preds)\n",
        "    acc = torch.sum(torch.argmax(preds, dim=1) == torch.argmax(labels, dim=1))\n",
        "    running_loss += loss.item() # 將每一訓練完的結果加回總數\n",
        "    \n",
        "    running_corrects += (acc / len(labels))\n",
        "  else:\n",
        "    # pass\n",
        "    training_epoch_loss, training_epoch_accuracy = record_epoch(\n",
        "        title=\"Training\",\n",
        "        losses=running_loss,\n",
        "        corrects=running_corrects,\n",
        "        loader_lenth=len(training_loader)\n",
        "        )\n",
        "    \n",
        "    running_loss_history.append(training_epoch_loss)\n",
        "    running_correct_history.append(training_epoch_accuracy)\n",
        "    \n",
        "    # val_running_loss, val_running_corrects = validation_process()\n",
        "    # val_epoch_loss, val_epoch_accuracy = record_epoch(\n",
        "    #     title='Validation',\n",
        "    #     losses=val_running_loss,\n",
        "    #     corrects=val_running_corrects,\n",
        "    #     loader_lenth=len(validation_loader)\n",
        "    #     )\n",
        "    \n",
        "    # val_running_loss_history.append(val_epoch_loss)\n",
        "    # val_running_correct_history.append(val_epoch_accuracy)\n",
        "\n",
        "for e in range(epochs):\n",
        "  traing_process()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnYV3g4ClXQ9",
        "outputId": "6504a86c-6082-4a66-d1e3-502fabbf04ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Training loss: 1.1285\n",
            "Training accuracy: 0.3125\n",
            "10\n",
            "Training loss: 1.1078\n",
            "Training accuracy: 0.3333\n",
            "10\n",
            "Training loss: 1.0926\n",
            "Training accuracy: 0.3333\n",
            "10\n",
            "Training loss: 1.0759\n",
            "Training accuracy: 0.3333\n",
            "10\n",
            "Training loss: 1.0653\n",
            "Training accuracy: 0.3458\n",
            "10\n",
            "Training loss: 1.0495\n",
            "Training accuracy: 0.5167\n",
            "10\n",
            "Training loss: 1.0353\n",
            "Training accuracy: 0.6875\n",
            "10\n",
            "Training loss: 1.0242\n",
            "Training accuracy: 0.7750\n",
            "10\n",
            "Training loss: 1.0064\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.9931\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.9776\n",
            "Training accuracy: 0.8417\n",
            "10\n",
            "Training loss: 0.9559\n",
            "Training accuracy: 0.8500\n",
            "10\n",
            "Training loss: 0.9371\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.9238\n",
            "Training accuracy: 0.8542\n",
            "10\n",
            "Training loss: 0.8965\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.8739\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.8515\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.8405\n",
            "Training accuracy: 0.8542\n",
            "10\n",
            "Training loss: 0.7937\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.7689\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.7382\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.7151\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.7063\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.6787\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.6394\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.6275\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.6393\n",
            "Training accuracy: 0.7958\n",
            "10\n",
            "Training loss: 0.6041\n",
            "Training accuracy: 0.8208\n",
            "10\n",
            "Training loss: 0.5899\n",
            "Training accuracy: 0.8292\n",
            "10\n",
            "Training loss: 0.5447\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.5569\n",
            "Training accuracy: 0.8500\n",
            "10\n",
            "Training loss: 0.5399\n",
            "Training accuracy: 0.8417\n",
            "10\n",
            "Training loss: 0.5132\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.5134\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.5099\n",
            "Training accuracy: 0.8417\n",
            "10\n",
            "Training loss: 0.4805\n",
            "Training accuracy: 0.8417\n",
            "10\n",
            "Training loss: 0.4740\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.4536\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.4417\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.4537\n",
            "Training accuracy: 0.8417\n",
            "10\n",
            "Training loss: 0.4330\n",
            "Training accuracy: 0.8500\n",
            "10\n",
            "Training loss: 0.4330\n",
            "Training accuracy: 0.8542\n",
            "10\n",
            "Training loss: 0.4101\n",
            "Training accuracy: 0.8625\n",
            "10\n",
            "Training loss: 0.4474\n",
            "Training accuracy: 0.8083\n",
            "10\n",
            "Training loss: 0.4039\n",
            "Training accuracy: 0.8542\n",
            "10\n",
            "Training loss: 0.4133\n",
            "Training accuracy: 0.8750\n",
            "10\n",
            "Training loss: 0.3900\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3845\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.3814\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.3780\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.3584\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3696\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.3517\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3630\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3390\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3375\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3190\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3395\n",
            "Training accuracy: 0.8667\n",
            "10\n",
            "Training loss: 0.3230\n",
            "Training accuracy: 0.8875\n",
            "10\n",
            "Training loss: 0.3371\n",
            "Training accuracy: 0.8792\n",
            "10\n",
            "Training loss: 0.3017\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.3202\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.2999\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.3238\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.3010\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.3369\n",
            "Training accuracy: 0.8708\n",
            "10\n",
            "Training loss: 0.3070\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2911\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.2731\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.2778\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.2810\n",
            "Training accuracy: 0.9125\n",
            "10\n",
            "Training loss: 0.2860\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2807\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2886\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2861\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2663\n",
            "Training accuracy: 0.8917\n",
            "10\n",
            "Training loss: 0.2649\n",
            "Training accuracy: 0.9250\n",
            "10\n",
            "Training loss: 0.2486\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2597\n",
            "Training accuracy: 0.9042\n",
            "10\n",
            "Training loss: 0.2551\n",
            "Training accuracy: 0.9250\n",
            "10\n",
            "Training loss: 0.2574\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2323\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2372\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2377\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2358\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2358\n",
            "Training accuracy: 0.9375\n",
            "10\n",
            "Training loss: 0.2269\n",
            "Training accuracy: 0.9500\n",
            "10\n",
            "Training loss: 0.2326\n",
            "Training accuracy: 0.9500\n",
            "10\n",
            "Training loss: 0.2334\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2246\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2126\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2102\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2330\n",
            "Training accuracy: 0.9417\n",
            "10\n",
            "Training loss: 0.2171\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1979\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2126\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2168\n",
            "Training accuracy: 0.9417\n",
            "10\n",
            "Training loss: 0.2056\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1900\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1904\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1938\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1904\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1955\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.2060\n",
            "Training accuracy: 0.9417\n",
            "10\n",
            "Training loss: 0.1910\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1875\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1740\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1806\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1752\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1690\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1691\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1640\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1612\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1624\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1582\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1592\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1556\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1518\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1544\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1707\n",
            "Training accuracy: 0.9417\n",
            "10\n",
            "Training loss: 0.1457\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1589\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1416\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1438\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1410\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1394\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1392\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1422\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1387\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1388\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1403\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1307\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1339\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1323\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1300\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1341\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1381\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1218\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1263\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1263\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1308\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1210\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1195\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1168\n",
            "Training accuracy: 0.9625\n",
            "10\n",
            "Training loss: 0.1203\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1109\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1160\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1081\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1398\n",
            "Training accuracy: 0.9542\n",
            "10\n",
            "Training loss: 0.1072\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1062\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1207\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1090\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1218\n",
            "Training accuracy: 0.9542\n",
            "10\n",
            "Training loss: 0.1060\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1068\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1040\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1031\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1145\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0963\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1018\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.1186\n",
            "Training accuracy: 0.9542\n",
            "10\n",
            "Training loss: 0.1016\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0957\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0974\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0978\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0918\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0995\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0890\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0963\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0988\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0898\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0864\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0856\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0896\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0856\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0998\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0823\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0991\n",
            "Training accuracy: 0.9542\n",
            "10\n",
            "Training loss: 0.0827\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0890\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0796\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0809\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0903\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0778\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0853\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0807\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0803\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0771\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0767\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0766\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0762\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0741\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0731\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0725\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0726\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0760\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0781\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0726\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0708\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0708\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0760\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0750\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0695\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0692\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0738\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0690\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0668\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0771\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0678\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0659\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0723\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0645\n",
            "Training accuracy: 0.9750\n",
            "10\n",
            "Training loss: 0.0703\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0636\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0651\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0658\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0640\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0814\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0688\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0629\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0604\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0638\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0690\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0616\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0649\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0672\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0607\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0594\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0718\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0629\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0579\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0570\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0591\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0589\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0583\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0570\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0569\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0633\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0570\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0557\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0579\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0549\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0544\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0701\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0703\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0679\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0537\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0544\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0528\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0519\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0510\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0509\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0521\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0509\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0568\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0557\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0499\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0508\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0489\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0491\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0650\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0478\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0629\n",
            "Training accuracy: 0.9667\n",
            "10\n",
            "Training loss: 0.0479\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0499\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0468\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0521\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0502\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0496\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0465\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0463\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0456\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0463\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0455\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0449\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0456\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0455\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0443\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0441\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0456\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0445\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0442\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0489\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0437\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0510\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0430\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0433\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0444\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0432\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0427\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0418\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0414\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0429\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0415\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0455\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0422\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0418\n",
            "Training accuracy: 0.9875\n",
            "10\n",
            "Training loss: 0.0410\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0414\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0471\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0411\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0402\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0539\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0414\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0412\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0398\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0408\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0398\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0395\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0393\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0390\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0419\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0404\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0387\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0448\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0378\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0383\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0379\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0372\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0374\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0374\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0444\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0380\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0380\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0383\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0383\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0359\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0360\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0372\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0359\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0371\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0405\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0363\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0352\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0348\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0350\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0354\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0421\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0348\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0351\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0388\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0344\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0338\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0469\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0337\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0341\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0338\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0353\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0458\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0333\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0337\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0339\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0329\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0435\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0329\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0329\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0327\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0323\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0384\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0328\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0326\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0327\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0327\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0319\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0352\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0365\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0341\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0314\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0314\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0310\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0326\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0331\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0363\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0315\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0305\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0307\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0306\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0316\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0315\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0363\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0305\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0305\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0296\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0302\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0323\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0289\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0293\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0293\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0295\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0287\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0315\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0291\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0287\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0288\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0347\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0297\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0293\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0281\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0285\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0286\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0337\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0278\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0289\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0276\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0277\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0275\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0274\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0275\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0274\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0272\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0270\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0272\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0295\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0270\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0269\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0265\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0267\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0269\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0263\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0270\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0262\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0266\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0264\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0268\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0263\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0261\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0266\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0257\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0257\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0260\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0255\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0250\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0255\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0253\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0313\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0261\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0311\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0255\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0253\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0253\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0255\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0249\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0305\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0308\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0248\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0268\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0302\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0246\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0306\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0241\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0241\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0418\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0245\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0246\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0238\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0273\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0235\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0234\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0293\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0239\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0232\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0235\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0234\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0234\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0230\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0248\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0329\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0232\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0230\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0227\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0292\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0227\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0233\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0312\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0226\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0229\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0229\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0227\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0220\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0221\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0319\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0260\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0275\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0267\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0218\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0222\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0222\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0309\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0223\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0220\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0219\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0267\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0219\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0223\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0213\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0272\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0210\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0268\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0214\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0207\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0215\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0207\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0224\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0206\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0207\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0211\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0215\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0205\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0206\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0208\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0209\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0206\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0205\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0202\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0256\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0269\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0199\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0202\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0201\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0198\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0198\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0197\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0247\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0201\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0201\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0240\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0198\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0254\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0196\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0192\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0284\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0192\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0194\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0286\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0191\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0189\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0195\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0188\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0193\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0190\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0190\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0185\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0189\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0186\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0188\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0188\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0189\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0189\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0232\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0183\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0191\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0246\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0183\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0187\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0188\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0180\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0190\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0180\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0238\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0183\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0180\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0182\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0178\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0180\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0179\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0183\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0225\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0254\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0176\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0175\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0178\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0178\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0184\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0173\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0236\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0173\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0172\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0176\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0170\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0172\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0170\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0175\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0243\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0178\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0167\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0167\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0167\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0164\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0237\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0279\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0202\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0164\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0164\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0218\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0165\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0162\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0160\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0165\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0161\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0170\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0204\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0161\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0159\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0162\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0159\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0160\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0181\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0158\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0188\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0160\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0157\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0154\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0155\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0207\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0155\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0163\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0158\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0154\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0176\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0153\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0152\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0152\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0155\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0150\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0155\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0151\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0151\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0149\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0149\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0157\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0199\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0150\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0150\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0147\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0176\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0147\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0146\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0146\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0149\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0148\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0174\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0191\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0146\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0144\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0145\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0144\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0166\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0148\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0142\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0144\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0146\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0141\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0141\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0139\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0140\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0201\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0142\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0139\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0178\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0142\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0137\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0142\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0138\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0175\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0134\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0135\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0141\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0134\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0134\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0138\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0135\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0153\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0134\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0173\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0181\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0133\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0177\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0132\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0173\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0132\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0130\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0135\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0130\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0131\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0130\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0134\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0129\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0128\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0129\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0129\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0128\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0128\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0171\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0127\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0128\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0127\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0125\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0131\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0125\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0182\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0145\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0124\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0181\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0125\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0124\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0127\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0175\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0120\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0120\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0120\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0119\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0119\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0119\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0120\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0189\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0133\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0115\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0116\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0115\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0116\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0135\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0115\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0166\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0115\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0116\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0112\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0148\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0144\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0110\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0112\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0111\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0160\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0157\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0141\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0137\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0110\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0131\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0110\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0156\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0108\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0109\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0108\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0107\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0109\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0125\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0106\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0110\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0108\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0107\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0107\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0122\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0107\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0106\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0105\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0106\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0123\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0104\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0143\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0108\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0104\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0105\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0153\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0104\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0108\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0105\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0103\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0101\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0101\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0100\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0100\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0132\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0101\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0120\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0100\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0098\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0104\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0136\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0099\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0132\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0099\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0099\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0099\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0099\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0098\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0096\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0097\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0131\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0096\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0130\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0124\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0096\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0098\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0126\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0094\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0094\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0094\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0092\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0091\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0127\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0092\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0094\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0091\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0092\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0090\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0092\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0093\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0091\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0090\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0091\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0090\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0131\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0106\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0119\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0090\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0089\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0087\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0087\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0090\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0087\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0102\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0087\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0087\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0100\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0101\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0116\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0084\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0114\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0086\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0085\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0084\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0117\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0082\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0113\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0082\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0124\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0081\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0081\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0083\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0095\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0082\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0082\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0094\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0081\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0081\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0091\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0080\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0118\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0081\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0079\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0109\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0115\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0078\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0088\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0077\n",
            "Training accuracy: 1.0000\n",
            "10\n",
            "Training loss: 0.0076\n",
            "Training accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(running_correct_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "PbrGk_rE3Fvc",
        "outputId": "bae6b513-b5bb-44c8-fdfe-280bc62039cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f824a7a1850>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(running_loss_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oDnNucrS3T-6",
        "outputId": "19145942-157c-4d43-ad77-510d71eecbda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8247c3a190>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}